# 决策树
## 决策树的优点
简单的理解和解释，树木可视化。
需要很少的数据准备，其他技术通常需要数据归一化，需要创建虚拟变量，并删除控制，次模块不支持缺失值。
使用树的成本(即，预测数据)在用于训练树的数据点的数量上是对数的。
能够处理数字和分类数据，其他技术通常专门用户分析只有一种变量类型的数据集。
能够处理多输出问题。
使用白盒模型，如果给定的情况在模型中可以观察到，那么条件的解释很容易用布尔逻辑来解释，相比之下，在黑盒子模型(例如，在人造神经网络中)，结果可能更难解释。
可以使用统计测试验证模型，这样可以说明模型的可靠性。
即使其假设被数据生成的真实模型有些违反，表现良好。

# 决策树的缺点包括：
决策树学习者可以创建不能很好地推广数据的过于复杂的树，这被成为过拟合。修剪(不支持当前)的机制，设置叶节点所需的最小样本数或
设置树的最大深度是避免问题的必要条件
决策树可能不稳定，因为数据的小变化可能回导致完全不同的树生成，通过使用合奏中的决策树来减轻这个问题。
在最优化的几个方面甚至简单的概念中