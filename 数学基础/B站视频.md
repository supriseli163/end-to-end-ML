# 视频第一集
## 1.什么时候可以使用机器学习
1. 有规律可以学习
2. 编程很难做到
3. 有能够学到规律的数据
## PLA Perceptron Learning Algorithm

# 参考文章
1. https://www.cnblogs.com/HappyAngel/p/3456762.html
# 第二集
##理解为什么机器可以学习-Hoeffding不等式
PCA可学习性很大程度上由所需的训练样本数量决定。随着问题规模的增长
所带来的所需训练样本的增长为学习问题的样本复杂度(sample complexity).
在多数实际问题中，最限制学习器成功的因素是有限的可用的训练数据。
## (霍夫丁)Hoeffding边界
### 描述问题
现在我们来更准确的描述我们要解决的问题，令D代表学习器可以观察的训练
数据集合，而P代表整个数据集合背后满足的概率分布。令Ein(h)代表假设h的
训练错误率(在机器学习基石课程中，该错误率被称为in-same error),确切地说，
Ein(h)是数据集D中被h误分类的训练数据所占比例,Ein(h)概率分布P上的。
现在令g代表H中最小训练错误率的假设。
问：多少训练数据才足以保证真实错误率Eout(h)和训练错误率Ein(h)很接近，并且接近0.
### Hoffding不等式
https://www.jianshu.com/p/9fee1fc060c0


